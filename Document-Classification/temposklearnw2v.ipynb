{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from texter.utils.config_utils import sklearn_model_config as smc\n",
    "from texter.utils.config_utils import sklearn_data_config as sdc\n",
    "\n",
    "from texter.utils.io_utils import load_config, save_config, load_model, save_model \n",
    "from texter.utils.io_utils import save_text_model, load_text_model\n",
    "\n",
    "from texter.utils import text_utils as tu\n",
    "from texter.utils.eval_utils import classifier_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load the  hyperparams from the json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "smc_dict = dict(name=\"SVC\")\n",
    "save_config(\"smc_doc_SVC.json\", smc_dict)\n",
    "\n",
    "sdc_w2v = dict(text_path='../../../citi/citi_rest/data/raw_data/',\n",
    "                 text_labels=['class_1', 'class_2', 'class_3'],\n",
    "                 processing_type='word2vec',\n",
    "                 w2v_path=\"../../data/others/GoogleNews-vectors-negative300-SLIM.bin\")\n",
    "save_config(\"sdc_doc_w2v.json\", sdc_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdc_config = load_config(\"sdc_doc_w2v.json\")\n",
    "smc_config = load_config(\"smc_doc_SVC.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Slim-Google-vectors-negative300.bin pretrained embeddings\n",
      "Considering only ['ADJ', 'NOUN']\n",
      "Averaging the Word Embeddings...\n",
      "Loading Slim-Google-vectors-negative300.bin pretrained embeddings\n",
      "Considering only ['ADJ', 'NOUN']\n",
      "Averaging the Word Embeddings...\n",
      "classification model configured to use SVC algorithm.\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test, fitted_text_model = sdc(**sdc_config)\n",
    "model = smc(**smc_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'please choose tfidf to get a fitted model'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_text_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_text_model(\"svc_text\", fitted_text_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample predictions\n",
    "\n",
    "s = \"\"\"Ayahuasca emerged again in the early 1960s with the counterculture movement.\\n \n",
    "Beat writers like William Burroughs, Allen Ginsberg, and Jack Kerouac all described \\n\n",
    "their experiences with ayahuasca, most famously in Burroughs's book The Yage Letters. \"\"\"\n",
    "\n",
    "t = \"pandas is here for the day\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(\"svc_w2v\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.fit(x_train, y_train).predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load saved model\n",
    "rf = load_model(\"svc_w2v\")\n",
    "y_pred=rf.fit(x_train, y_train).predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. score: 0.0\n",
      "2. classification model report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         1\n",
      "          1       0.00      0.00      0.00         2\n",
      "          2       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.00      0.00      0.00         3\n",
      "\n",
      "3. confusion matrix:\n",
      "[[0 0 1]\n",
      " [0 0 2]\n",
      " [0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(classifier_report(rf, x_test, y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vt = tu.sklearn_text_vectorizer(t, model=\"word2vec\", \n",
    "#                                w2v_path=\"../../data/others/GoogleNews-vectors-negative300-SLIM.bin\")\n",
    "\n",
    "vtt = tu.sklearn_text_vectorizer(s, model=\"word2vec\",fitted_model=fitted_text_model)\n",
    "model.predict(vtt)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.26, 0.28, 0.46]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(vtt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_text_model(\"rf_v1_tfidf\", fitted_text_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Slim-Google-vectors-negative300.bin pretrained embeddings\n",
      "Considering only ['ADJ', 'NOUN']\n",
      "Averaging the Word Embeddings...\n"
     ]
    }
   ],
   "source": [
    "fm = tu.sklearn_text_vectorizer(t, model=\"word2vec\", \n",
    "                                w2v_path=\"../../data/others/GoogleNews-vectors-negative300-SLIM.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.predict(fm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
